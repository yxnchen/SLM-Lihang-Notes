# 隐马尔可夫模型

[TOC]



> 隐马尔可夫模型（hidden Markov model，HMM）是用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型

## 10.1 隐马尔可夫模型的基本概念

### 10.1.1 隐马尔可夫模型的定义

- **定义**：隐马尔可夫模型是关于<u>*时序*</u>的概率模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列称为**状态序列**（state sequence）；每个状态生成一个观测，而由此产生的观测的随机序列称为**观测序列**（observation sequence）。序列的每一个位置又可以看作是<u>*一个时刻*</u>；
- 隐马尔可夫模型由<u>*初始概率分布*</u>、<u>*状态转移概率分布*</u>以及<u>*观测概率分布*</u>确定；

- **模型形式**：

  - 设$Q=\{q_1,\dots,q_N\}$是所有可能的状态的集合，$V=\{v_1,\dots,v_M\}]$是所有可能的观测的集合；

  - $I=(i_1,i_2,\dots,i_T)​$是长度为$T​$的状态序列，$O=(o_1,i_2,\dots,i_T)​$是对应的观测序列；

  - $A$是状态转移概率矩阵：
    $$
    A=\left[a_{ij}\right]_{N\times N}
    $$
    其中$a_{ij}=P(i_{t+1}=q_j|i_t=q_i), i=1,2,\dots,N; j=1,2,\dots,N$是在时刻$t$处于状态$q_i$的条件下，在时刻$t+1$转移到状态$q_j$的概率；

  - $B​$是观测概率矩阵：
    $$
    B=\left[b_{j}(k)\right]_{N\times M}
    $$
    其中$b_{j}(k)=P(o_t=v_k|i_t=q_j), k=1,2,\dots,M;j=1,2,\dots,N​$是在时刻$t​$处于状态$q_i​$的条件下，生成观测$v_k​$的概率；

  - $\pi$是初始状态概率向量：
    $$
    \pi=(\pi_i)
    $$
    其中$\pi_i=P(i_1=q_i), i=1,2,\dots,N$是时刻$t=1$处于状态$q_i$的概率；

- 隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵$A$以及观测概率矩阵$B$决定；$\pi$和$A$决定状态序列，$B$决定观测序列，因此隐马尔可夫模型$\lambda$可以用三元符号表示

$$
\lambda=(A,B,\pi)
$$

- 隐马尔可夫模型做了两个基本假设：

  1. **齐次马尔可夫性假设**，即假设隐藏的马尔可夫链在任意时刻$t$的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻$t$无关：
     $$
     P(i_t|i_{t-1},o_{t-1},\dots,i_1,o_1)=P(i_t|i_{t-1}), \quad t=1,2,\dots,T
     $$

  2. **观测独立性假设**，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关：
     $$
     P(o_t|i_T,o_T,i_{T-1},o_{T-1},\dots,i_{t+1},o_{t+1},i_{t-1},o_{t-1},\dots,i_1,o_1)=P(o_t|i_t)
     $$

- 隐马尔可夫模型可以用于标注，这是状态对应着标记（标注问题是给定观测序列去预测其对应的标记序列）；

### 10.1.2 观测序列的生成过程

- **观测序列生成算法**：
  1. **输入**隐马尔可夫模型$\lambda=(A,B,\pi)​$，观测序列长度$T​$；
  2. 按照初始状态分布$\pi​$产生状态$i_1​$，令$t=1​$；
  3. 按照状态$i_t$的观测概率分布$b_{i_t}(k)$生成$o_{t}$；
  4. 按照状态$i_t$的状态转移概率分布$\{a_{i_t i_{t+1}}\}$产生状态$i_{t+1}\in Q$；
  5. 令$t=t+1$，如果$t<T$，转到步骤（3），否则终止；

### 10.1.3 隐马尔可夫模型的3个基本问题

1. 概率计算问题：给定模型$\lambda=(A,B,\pi)​$和观测序列$O=(o_1,i_2,\dots,i_T)​$，计算在次模型下观测序列出现的概率$P(O|\lambda)​$；
2. 学习问题：已知观测序列$O=(o_1,i_2,\dots,i_T)​$，估计模型$\lambda=(A,B,\pi)​$参数，使得在该模型下观测序列概率$P(O|\lambda)​$最大，即用极大似然估计法估计参数；
3. 预测问题，也叫**解码问题**（decoding）：已知模型$\lambda=(A,B,\pi)​$和观测序列$O=(o_1,i_2,\dots,i_T)​$，求对给定观测序列条件概率$P(I|O)​$最大的状态序列$I=(i_1,i_2,\dots,i_T)​$，即给定观测序列，求最有可能的对应的状态序列；

## 10.2 概率计算问题

### 10.2.1 直接计算法

- 直接计算法是通过列举所有可能的长度为$T​$的状态序列$I=(i_1,i_2,\dots,i_T)​$，求各个状态序列与观测序列的联合概率$P(O,I|\lambda)​$，然后对所有可能的状态序列求和得到$P(O|\lambda)​$；
- 状态序列$I=(i_1,i_2,\dots,i_T)​$的概率是

$$
P(I|\lambda)=\pi_{i_1}a_{i_1i_2}a_{i_1i_3}\cdots a_{i_{T-1}i_T}
$$

- 对于给定$I=(i_1,i_2,\dots,i_T)$，观测序列$O=(o_1,i_2,\dots,i_T)$的概率是

$$
P(O|I,\lambda)=b_{i_1}(o_1)b_{i_2}(o_2)\cdots b_{i_T}(o_T)
$$

- $I$与$O$的联合概率

$$
\begin{aligned}
P(O,I|\lambda)&=P(O|I,\lambda)P(I|\lambda) \\
&=\pi_{i_1} b_{i_1}(o_1) a_{i_1i_2} b_{i_2}(o_2) \cdots a_{i_{T-1}i_T} b_{i_T}(o_T)
\end{aligned}
$$

- 对所有可能状态序列求和，得到

$$
\begin{aligned}
P(O|\lambda)&=\sum_{I}P(O|I,\lambda)P(I|\lambda) \\
&=\sum_{i_1,i_2,\dots,i_T}\pi_{i_1} b_{i_1}(o_1) a_{i_1i_2} b_{i_2}(o_2) \cdots a_{i_{T-1}i_T} b_{i_T}(o_T)
\end{aligned}
$$

- 此方法计算量大，计算复杂度为$O(TN^T)$；

### 10.2.2 前向算法

- **前向概率**：给定隐马尔科夫模型$\lambda$，定义到时刻$t$部分观测序列为$o_1,o_2,\dots,o_t$且